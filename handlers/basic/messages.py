import asyncio
from datetime import datetime, timedelta

from PIL import Image
from aiogram import Router, F, Bot
from aiogram.enums import ChatAction
from aiogram.types import Message, PhotoSize, ReplyKeyboardMarkup, KeyboardButton, InlineKeyboardButton
import logging
import os

from API.OllamaAPI import OllamaAPI
from Database.Database import Database

router = Router()
ollama = OllamaAPI()
db = Database()
logger = logging.getLogger(__name__)

# –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —á–∞—Ç–∞
clear_chat_button = ReplyKeyboardMarkup(
    keyboard=[[KeyboardButton(text="üóë –û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç")]],
    resize_keyboard=True,
    one_time_keyboard=False
)


async def show_typing_status(chat_id: int, bot: Bot):
    while True:
        await bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
        await asyncio.sleep(3)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±–æ—Ä–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —á–∞—Ç–∞
async def build_chat_context(user_id: int) -> list:
    """Forms the history of chat for transfer to the neural network."""
    history = await db.get_recent_chat_history(user_id, limit=25)

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ system-—Å–æ–æ–±—â–µ–Ω–∏–µ
    messages = [{"role": "system", "content": "You are telegram bot based on AI Gemma3. Bot created by @FLARMIX."
                                              "Do not use any LaTeX, HTML, or Markdown formatting in your answers. "
                                              "Always reply in plain text. Avoid symbols like ^, _, $, <, >,"
                                              " and do not use tags such as <sup>, <sub>, or equations."}]

    for msg in history:
        messages.append({"role": "user", "content": msg["user_content"]})
        messages.append({"role": "assistant", "content": msg["ai_content"]})

    return messages


# Processing of a text request
@router.message(F.text & ~F.text.startswith('/') & ~F.text.in_(
    ["üóë –û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç", "–º–µ–Ω—é", "–ú–µ–Ω—é", "–ü–æ–º–æ—â—å", "–ø–æ–º–æ—â—å", "–ù–∞—Å—Ç—Ä–æ–π–∫–∏", "–Ω–∞—Å—Ç—Ä–æ–π–∫–∏"]))
async def handle_message(message: Message):
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —á–∞—Ç –≥—Ä—É–ø–ø–æ–π/—Å—É–ø–µ—Ä–≥—Ä—É–ø–ø–æ–π
    if message.chat.type in ["group", "supergroup"]:
        flag = True
        # –î–ª—è –≥—Ä—É–ø–ø–æ–≤—ã—Ö —á–∞—Ç–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ prompt –≤ –Ω–∞—á–∞–ª–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        if not message.text.lower().startswith("prompt"):
            return  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ prompt
    else:
        flag = False

    user_id = message.from_user.id

    user_stats = await db.get_user_stats(user_id)
    current_tokens = user_stats.get("current_tokens", 0)
    max_tokens = user_stats.get("max_tokens")  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤
    last_tokens_got = user_stats.get("last_tokens_got", None)

    now = datetime.now()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–æ—à–ª–æ –ª–∏ 24 —á–∞—Å–∞ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è
    if last_tokens_got:
        last_tokens_got = datetime.strptime(last_tokens_got, "%Y-%m-%d %H:%M:%S")
    else:
        last_tokens_got = now - timedelta(days=1)  # –ï—Å–ª–∏ NULL, –∑–Ω–∞—á–∏—Ç –ø–µ—Ä–≤—ã–π —Ä–∞–∑

    if now - last_tokens_got >= timedelta(days=1):
        # –ï—Å–ª–∏ –±–∞–ª–∞–Ω—Å –≤—ã—à–µ –ª–∏–º–∏—Ç–∞, –Ω–µ –ø–æ–ø–æ–ª–Ω—è–µ–º
        if current_tokens < max_tokens:
            current_tokens += max_tokens - current_tokens  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            await db.update_user_stat("current_tokens", current_tokens, user_id)

        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è
        await db.update_user_stat("last_tokens_got", now.strftime("%Y-%m-%d %H:%M:%S"), user_id)

    if current_tokens < 1:
        # –ï—Å–ª–∏ –≤ –±–∞–∑–µ last_tokens_got –ø–æ—á–µ–º—É-—Ç–æ —Ö—Ä–∞–Ω–∏—Ç—Å—è —Å—Ç—Ä–æ–∫–æ–π, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
        if isinstance(last_tokens_got, str):
            last_tokens_got = datetime.strptime(last_tokens_got, "%Y-%m-%d %H:%M:%S")

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–ª–µ–¥—É—é—â–µ–µ –Ω–∞—á–∏—Å–ª–µ–Ω–∏–µ (24 —á–∞—Å–∞ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ)
        next_refill_time = last_tokens_got + timedelta(hours=24)

        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è
        now = datetime.now()

        # –í—ã—á–∏—Å–ª—è–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è –¥–æ –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è
        time_left = next_refill_time - now  # –≠—Ç–æ —É–∂–µ timedelta
        hours, remainder = divmod(time_left.total_seconds(), 3600)
        minutes = remainder // 60

        await message.reply(
            f"–£ –≤–∞—Å –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å —Ç–æ–∫–µ–Ω—ã! –ü—Ä–∏—Ö–æ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ {int(hours)} —á. {int(minutes)} –º–∏–Ω. –∏–ª–∏ –ø–æ–ø–æ–ª–Ω–∏—Ç–µ –±–∞–ª–∞–Ω—Å.")
        return

    typing_action = asyncio.create_task(show_typing_status(message.chat.id, message.bot))
    await db.create_user(user_id)

    try:
        prompt = message.text
        if flag:
            prompt = prompt[len("prompt")::]

        chat_context = await build_chat_context(user_id)  # Get chat history

        response_data, tokens = await ollama.generate_response(chat_history=chat_context, user_prompt=prompt,
                                                               max_tokens=800)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ (–æ—Ç–≤–µ—Ç –æ—Ç AI)
        ai_content = response_data.get("content", "")

        if not ai_content:
            await message.reply("ü§ñ –ú–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–≥–ª–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç.")
            return

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω—ã
        current_tokens = await db.get_user_stats(user_id)
        current_tokens = current_tokens.get("current_tokens")
        print(current_tokens)
        await db.update_user_stat("current_tokens", current_tokens - 1, user_id)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        await db.save_message(user_id, prompt, ai_content)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        await message.reply(ai_content, reply_markup=clear_chat_button, parse_mode=None)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞: {str(e)}", exc_info=True)
        await message.reply("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞.")
    finally:
        typing_action.cancel()


# Image processing
@router.message(F.photo)
async def handle_photo(message: Message):
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —á–∞—Ç –≥—Ä—É–ø–ø–æ–π/—Å—É–ø–µ—Ä–≥—Ä—É–ø–ø–æ–π
    if message.chat.type in ["group", "supergroup"]:
        flag = True
        # –î–ª—è –≥—Ä—É–ø–ø–æ–≤—ã—Ö —á–∞—Ç–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ prompt –≤ –Ω–∞—á–∞–ª–µ
        if not message.text.lower().startswith("prompt"):
            return  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ prompt
    else:
        flag = False

    typing_action = asyncio.create_task(show_typing_status(message.chat.id, message.bot))
    user_id = message.from_user.id
    if not await db.check_user_exists(user_id):
        await db.create_user(user_id)

    try:
        photo: PhotoSize = message.photo[-1]
        file = await message.bot.get_file(photo.file_id)

        # Load the image in memory (without storing to disk)
        await message.bot.download_file(file.file_path, "temp_files/temp_picture.jpg")

        # Reduce the image for transmission to the neural network
        with Image.open("temp_files/temp_picture.jpg") as img:
            original_width, original_height = img.width, img.height

            changed_size = (original_width // 2, original_height // 2)

            resized_img = img.resize(changed_size)
            resized_img.save("temp_files/changed_temp_picture.jpg")

        base64_image = await ollama.encode_image_to_base64("temp_files/changed_temp_picture.jpg")

        # Get a text description (if any)
        user_caption = message.caption if message.caption else "–ß—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ?"
        if flag:
            user_caption = user_caption[len("prompt"):].strip()

        # Load the history of the chat
        chat_context = await build_chat_context(user_id)

        response, tokens = await ollama.generate_response(chat_history=chat_context, user_prompt=user_caption,
                                                          images=[base64_image], max_tokens=800)

        if not response.get('content'):
            await message.reply("ü§ñ –ú–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–≥–ª–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç.")
            return

        current_tokens = await db.get_user_stats(user_id)
        current_tokens = current_tokens.get("current_tokens")
        await db.update_user_stat("current_tokens", current_tokens - 1, user_id)
        await db.save_message(user_id, f"{user_caption}", response.get('content'))
        await message.reply(response.get('content'), reply_markup=clear_chat_button, parse_mode=None)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}", exc_info=True)
        await message.reply("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
    finally:
        typing_action.cancel()
        # Delete temporary files
        os.remove("temp_files/temp_picture.jpg")
        os.remove("temp_files/changed_temp_picture.jpg")


# Chat cleanup
@router.message(F.text == "üóë –û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç")
async def clear_chat(message: Message):
    user_id = message.from_user.id
    await db.delete_chat_history(user_id)
    await message.reply("‚úÖ –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π —É–¥–∞–ª–µ–Ω–∞.", reply_markup=clear_chat_button)
    return  # Stop the processing further!


# Help message
@router.message(F.text.in_(["–ø–æ–º–æ—â—å", "–ü–æ–º–æ—â—å"]))
async def help_button(message: Message):
    typing_action = asyncio.create_task(show_typing_status(message.chat.id, message.bot))
    messages = [{"role": "system", "content": "You are telegram bot based on AI Gemma3. Bot created by @FLARMIX. "
                                              "You can processing pictures."
                                              "Please avoid using any HTML tags in your responses. Provide plain text "
                                              "only."}]

    response = await ollama.generate_response(chat_history=messages,
                                              user_prompt="–†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ. –ß—Ç–æ —Ç—ã –º–æ–∂–µ—à—å, –∫—Ç–æ —Ç—ã. "
                                                          "–†–∞—Å—Å–∫–∞–∂–∏ —Ç–∞–∫ —á—Ç–æ–±—ã —è —á–∏—Ç–∞–ª –Ω–µ –º–Ω–æ–≥–æ, "
                                                          "–Ω–æ —Å—Ä–∞–∑—É –ø–æ–Ω—è–ª –≤—Å—ë –æ —Ç–µ–±–µ. "
                                                          "–í –∫–æ–Ω—Ü–µ –ø–æ–∂–µ–ª–∞–π –ø—Ä–∏—è—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–æ—Ç–æ–º.",
                                              max_tokens=300)

    await message.reply(response[0].get('content'))
    typing_action.cancel()
    return  # Stop the processing further!
